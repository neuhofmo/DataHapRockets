{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rockets notebook - more efficient and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# model imports\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "sns.set_style('white')\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(12345)\n",
    "seed = 12345  # for seeding individually\n",
    "\n",
    "pd.options.display.max_columns = 100  # max columns to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# models to enumerate\n",
    "model_list = [ExtraTreesClassifier(),\n",
    "RandomForestClassifier(),\n",
    "GradientBoostingClassifier(),\n",
    "XGBClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_name(classifier):\n",
    "    return str(classifier).split('(')[0]\n",
    "\n",
    "# so that: \n",
    "# get_classifier_name(model_list[0])  -> 'DecisionTreeClassifier'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train_data, has_labels=True):\n",
    "    \n",
    "    if has_labels:\n",
    "        target = train_data.loc[:,'class']\n",
    "\n",
    "    # parsing features and turnng them into vectors:\n",
    "    qq = list(range(1, 211, 7))\n",
    "    t_mat = train_data.iloc[:,qq].as_matrix()\n",
    "    qq = list(range(2, 211, 7))\n",
    "    x_mat = train_data.iloc[:,qq].as_matrix()\n",
    "    qq = list(range(3, 211, 7))\n",
    "    y_mat = train_data.iloc[:,qq].as_matrix()\n",
    "    qq = list(range(4, 211, 7))\n",
    "    z_mat = train_data.iloc[:,qq].as_matrix()\n",
    "    qq = list(range(5, 211, 7))\n",
    "    vx_mat = train_data.iloc[:,qq].as_matrix()\n",
    "    qq = list(range(6, 211, 7))\n",
    "    vy_mat = train_data.iloc[:,qq].as_matrix()\n",
    "    qq = list(range(7, 211, 7))\n",
    "    vz_mat = train_data.iloc[:,qq].as_matrix()\n",
    "\n",
    "    # 3 matrices:\n",
    "    ax_mat = np.gradient(vx_mat,0.5,axis=1)\n",
    "    ay_mat = np.gradient(vy_mat,0.5,axis=1)\n",
    "    az_mat = np.gradient(vz_mat,0.5,axis=1)\n",
    "    \n",
    "    # features:\n",
    "    v_total = np.sqrt(np.power(vx_mat,2)+np.power(vy_mat,2)+np.power(vz_mat,2))\n",
    "    a_total = np.sqrt(np.power(ax_mat,2)+np.power(ay_mat,2)+np.power(az_mat,2))\n",
    "    vx_mean = np.nanmean(vx_mat,axis=1)\n",
    "    vz_mean = np.nanmean(vz_mat,axis=1)\n",
    "    v_mean = np.nanmean(v_total,axis=1)\n",
    "    ax_mean = np.nanmean(ax_mat,axis=1)\n",
    "    az_mean = np.nanmean(az_mat,axis=1)\n",
    "    a_total_mean = np.nanmean(a_total,axis=1)\n",
    "    z_mean = np.nanmean(z_mat,axis=1)\n",
    "    vx_std = np.nanstd(vx_mat,axis=1)\n",
    "    vy_std = np.nanstd(vy_mat,axis=1)\n",
    "    vz_std = np.nanstd(vz_mat,axis=1)\n",
    "    v_std = np.nanstd(v_total,axis=1)\n",
    "    ax_std = np.nanstd(ax_mat,axis=1)\n",
    "    ay_std = np.nanstd(ay_mat,axis=1)\n",
    "    az_std = np.nanstd(az_mat,axis=1)\n",
    "    a_total_std = np.nanstd(a_total,axis=1)\n",
    "    y_std = np.nanstd(y_mat,axis=1)\n",
    "    N_data = len(train_data)\n",
    "    \n",
    "    notnan = ~np.isnan(x_mat)\n",
    "    p=np.zeros((N_data, 3))\n",
    "    roots = np.zeros((N_data, 2))\n",
    "    for i in range(N_data):\n",
    "        p[i,:] = np.polyfit(x_mat[i,notnan[i,:]], z_mat[i,notnan[i,:]],2)\n",
    "        roots[i]=np.roots(p[i])\n",
    "\n",
    "    poly_range = np.abs(roots[:,1]-roots[:,0])\n",
    "\n",
    "    poly_c0 = p[:,0]\n",
    "    poly_c1 = p[:,1]\n",
    "    poly_c2 = p[:,2]\n",
    "\n",
    "    poly_maxz = poly_c2-np.power(poly_c1,2)/float(4)/poly_c0\n",
    "    \n",
    "    # the dict that will later become the output data frame\n",
    "    return_dict = {'z_mean': z_mean, 'vx_mean': vx_mean, 'vz_mean': vz_mean, 'v_mean': v_mean,\n",
    "                   'ax_mean':ax_mean,'az_mean':az_mean,'a_total_mean':a_total_mean,\n",
    "                   'vx_std': vx_std, 'vz_std': vz_std, 'v_std': v_std, 'ax_std':ax_std,\n",
    "                   'az_std':az_std,'a_total_std':a_total_std, 'poly_c0':poly_c0,\n",
    "                   'poly_c1':poly_c1,'poly_c2':poly_c2, 'poly_range':poly_range,'poly_maxz':poly_maxz}\n",
    "    \n",
    "    # if it is the training set, add the labels\n",
    "    #     if has_labels: \n",
    "    #         return_dict['class'] = target\n",
    "    \n",
    "    \n",
    "    new_feat = pd.DataFrame(return_dict)\n",
    "    \n",
    "    # get first 5 seconds\n",
    "    qq = list(range(1,71))\n",
    "    X_raw = train_data.iloc[:,qq]\n",
    "    \n",
    "    #     X_new = new_feat.drop('class',axis=1)\n",
    "\n",
    "    # X = X_raw.join(X_new)  # Not using RAW at all\n",
    "    X = new_feat\n",
    "    if has_labels:\n",
    "        y = target\n",
    "        \n",
    "        # then split to train test\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "        \n",
    "        return X_train, X_val, y_train, y_val\n",
    "    else:\n",
    "        return X\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA LOADING - change work_folder to your folder\n",
    "work_folder = r'E:\\DataHack_2017'  # \n",
    "folder_join = os.path.join\n",
    "test_sample = folder_join(work_folder, 'test.csv')\n",
    "train_sample = folder_join(work_folder, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving two least common classes for later, for 'other' classification\n",
    "data_with23_16 = pd.read_csv(train_sample)\n",
    "data_no23_16 = data_with23_16[~data_with23_16['class'].isin([23,16])]  # removed 2 classes as other\n",
    "train_data, test_data = train_test_split(data_no23_16,test_size=0.2,random_state=123)  \n",
    "\n",
    "# TODO: remember 23,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_enumeration(X, y, model_list, scoring_list):\n",
    "    print(\"Running model enumeration:\")\n",
    "    st_st_time = time.time()  # timing\n",
    "    \n",
    "    for model in model_list:\n",
    "        name = get_classifier_name(model)  # the name of the model \n",
    "        st_time = time.time()\n",
    "        print(f\"Working on model {name}\")\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "        for scoring_type in scoring_list:\n",
    "            result = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring_type, n_jobs=-1)\n",
    "            print(f\"{name}: {scoring_type}: {result.mean():2.2f}, ({result.std():2.2f})\")\n",
    "        print(f\"{name} took {time.time() - st_time:2.2f}\")\n",
    "\n",
    "    print(f\"The run took {time.time() - st_st_time:2.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if that's the training set:\n",
    "X_train, X_val, y_train, y_val = process_data(train_data)\n",
    "\n",
    "# if that's the real set\n",
    "# X_test = process_data(test_data, has_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model enumeration:\n",
      "Working on model DecisionTreeClassifier\n",
      "DecisionTreeClassifier: accuracy: 0.49, (0.01)\n",
      "DecisionTreeClassifier: f1_weighted: 0.49, (0.01)\n",
      "DecisionTreeClassifier: precision_weighted: 0.49, (0.01)\n",
      "DecisionTreeClassifier: recall_weighted: 0.49, (0.01)\n",
      "DecisionTreeClassifier took 60.20\n",
      "Working on model ExtraTreesClassifier\n",
      "ExtraTreesClassifier: accuracy: 0.55, (0.01)\n",
      "ExtraTreesClassifier: f1_weighted: 0.54, (0.01)\n",
      "ExtraTreesClassifier: precision_weighted: 0.55, (0.01)\n",
      "ExtraTreesClassifier: recall_weighted: 0.55, (0.01)\n",
      "ExtraTreesClassifier took 62.54\n",
      "Working on model RandomForestClassifier\n",
      "RandomForestClassifier: accuracy: 0.55, (0.01)\n",
      "RandomForestClassifier: f1_weighted: 0.55, (0.01)\n",
      "RandomForestClassifier: precision_weighted: 0.55, (0.02)\n",
      "RandomForestClassifier: recall_weighted: 0.55, (0.01)\n",
      "RandomForestClassifier took 69.47\n",
      "Working on model GradientBoostingClassifier\n",
      "GradientBoostingClassifier: accuracy: 0.54, (0.01)\n",
      "GradientBoostingClassifier: f1_weighted: 0.53, (0.01)\n",
      "GradientBoostingClassifier: precision_weighted: 0.54, (0.01)\n",
      "GradientBoostingClassifier: recall_weighted: 0.54, (0.01)\n",
      "GradientBoostingClassifier took 2050.50\n",
      "Working on model XGBClassifier\n",
      "XGBClassifier: accuracy: 0.52, (0.01)\n",
      "XGBClassifier: f1_weighted: 0.51, (0.01)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-44052cf4c63f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# run model enumeration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscoring_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'precision_weighted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recall_weighted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_enumeration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-f52378c2e803>\u001b[0m in \u001b[0;36mmodel_enumeration\u001b[1;34m(X, y, model_list, scoring_list)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mscoring_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscoring_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{name}: {scoring_type}: {result.mean():2.2f}, ({result.std():2.2f})\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{name} took {time.time() - st_time:2.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             return_times=True)\n\u001b[1;32m--> 195\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run model enumeration\n",
    "scoring_list = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
    "model_enumeration(X_train, y_train, model_list, scoring_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [5, 10, 15, 20, 30, 50, 80, 100], 'max_depth': [2, 5, 7, 8, 9, 12, 14]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter optimization\n",
    "# TODO: grid\n",
    "# on randomForest and ExtraTrees\n",
    "param_grid = {'n_estimators': [5, 10, 15, 20, 30, 50, 80, 100],\n",
    "              'max_depth': [2, 5, 7, 8, 9, 12, 14],\n",
    "             }\n",
    "\n",
    "st_time = time.time()\n",
    "# for clf in (RandomForestClassifier(n_jobs=-1)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "print(f\"Working on model {clf}\")\n",
    "grid_clf = model_selection.GridSearchCV(clf, param_grid, scoring='accuracy', cv=10)\n",
    "# grid_clf = model_XGBClassifier(objective='multi:softprob',learning_rate=0.2,\n",
    "#                     subsample=0.7,\n",
    "#                     colsample_bytree=0.9,\n",
    "#                     colsample_bylevel=0.7,\n",
    "#                     max_depth=8,\n",
    "#                     nthread=4,\n",
    "#                     n_estimators=100,\n",
    "#                     seed=1234))selection.GridSearchCV(clf, param_grid, scoring='f1_weighted', cv=10)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "# print(f\"{clf}: {scoring_type}: {result.mean():2.2f}, ({result.std():2.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'max_depth': 14, 'n_estimators': 100}\n",
      "Best score: 0.61\n"
     ]
    }
   ],
   "source": [
    "# for random tree:\n",
    "print(f\"best params: {grid_clf.best_params_}\")\n",
    "print(f\"Best score: {grid_clf.best_score_:2.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgboost = {'learning_rate': [0.2/3, 0.2, 0.6, 0.9, 1.5], \n",
    "                      'max_depth': list(range(5,16)),\n",
    "                      'n_estimators': [50, 100, 150, 200]}\n",
    "st_time = time.time()\n",
    "# clf = RandomForestClassifier(n_jobs=-1)\n",
    "name = get_classifier_name(model)  # the name of the model\n",
    "print(f\"Working on model {name}\")\n",
    "# grid_clf = model_selection.GridSearchCV(clf, param_grid, scoring='accuracy', cv=10)\n",
    "xg_clf = XGBClassifier(objective='multi:softprob',\n",
    "                    subsample=0.7,\n",
    "                    colsample_bytree=0.9,\n",
    "                    colsample_bylevel=0.7,\n",
    "                    nthread=4,\n",
    "                    seed=seed)\n",
    "grid_xg_clf = model_selection.GridSearchCV(xg_clf, param_grid_xgboost, scoring='f1_weighted', cv=10)\n",
    "grid_xg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_PCA_on_data(data):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(data)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_tSNE_on_data(data, init='random'):\n",
    "    X_embedded = TSNE(n_components=2, init=init).fit_transform(X)\n",
    "    return X_embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also, run PCA\n",
    "X_pca = run_PCA_on_data(X_train)\n",
    "\n",
    "# no PCA\n",
    "X_tSNE = run_tSNE_on_data(X_train)\n",
    "# start with PCA\n",
    "X_tSNE = run_tSNE_on_data(X_train, init='pca')\n",
    "\n",
    "# tODO: run in classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_PCA(X_pca):\n",
    "    \"\"\"Plot PCA figure.\"\"\"\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    p1 = [x[0] for x in X_pca]\n",
    "    p2 = [x[1] for x in X_pca]\n",
    "\n",
    "    colors = [int(i % 500) for i in y_train]\n",
    "    plt.scatter(p1, p2, c=colors, s=3)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gbc = XGBClassifier(objective='multi:softprob',\n",
    "#                     learning_rate=0.2,\n",
    "#                     subsample=0.7,\n",
    "#                     colsample_bytree=0.9,\n",
    "#                     colsample_bylevel=0.7,\n",
    "#                     max_depth=8,\n",
    "#                     nthread=4,\n",
    "#                     n_estimators=100,\n",
    "#                     seed=1234)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
